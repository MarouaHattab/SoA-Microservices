# üöÄ Kafka Node.js Integration Project

Ce projet d√©montre l'int√©gration d'Apache Kafka avec Node.js pour la gestion des flux de donn√©es, ainsi que le stockage dans MongoDB et l'exposition via une API REST. Cette solution compl√®te permet de cr√©er un pipeline de donn√©es en temps r√©el, depuis la production de messages jusqu'√† leur consommation et leur visualisation via une API.

## üìã Table des mati√®res

- [Objectifs](#-objectifs)
- [Technologies utilis√©es](#-technologies-utilis√©es)
- [Architecture d√©taill√©e](#-architecture-d√©taill√©e)
- [Installation pas √† pas](#-installation-pas-√†-pas)
- [Configuration d√©taill√©e](#-configuration-d√©taill√©e)
- [Structure du projet](#-structure-du-projet)
- [Explication du code](#-explication-du-code)
- [Ex√©cution du syst√®me](#-ex√©cution-du-syst√®me)
- [API REST et endpoints](#-api-rest-et-endpoints)
- [Test des fonctionnalit√©s](#-test-des-fonctionnalit√©s)
- [Bonnes pratiques](#-bonnes-pratiques)
- [Extensions possibles](#-extensions-possibles)
- [Ressources](#-ressources)

## üéØ Objectifs

Ce projet vise √† atteindre les objectifs suivants :
- Comprendre les fondamentaux d'Apache Kafka et son utilisation avec Zookeeper
- Apprendre √† cr√©er et g√©rer des topics Kafka
- D√©velopper un producteur Kafka en Node.js qui g√©n√®re des messages
- Impl√©menter un consommateur Kafka en Node.js qui traite ces messages
- Int√©grer MongoDB pour le stockage persistant des messages
- Cr√©er une API REST avec Express.js pour exposer les messages stock√©s
- Mettre en place un syst√®me de traitement de donn√©es de bout en bout

## üíª Technologies utilis√©es

### Principales technologies
- **Apache Kafka (3.9.0)** : Plateforme de streaming d'√©v√©nements distribu√©e
- **Zookeeper** : Service de coordination pour Kafka
- **Node.js** : Environnement d'ex√©cution JavaScript c√¥t√© serveur
- **Express.js** : Framework web pour Node.js
- **MongoDB** : Base de donn√©es NoSQL orient√©e documents
- **Mongoose** : ODM (Object Data Modeling) pour MongoDB et Node.js
- **KafkaJS** : Client Kafka pour Node.js

### Outils suppl√©mentaires
- **npm** : Gestionnaire de paquets pour Node.js
- **Postman** (optionnel) : Outil de test d'API
- **MongoDB Compass** (optionnel) : Interface graphique pour MongoDB

## üèóÔ∏è Architecture d√©taill√©e

Le projet suit une architecture √† plusieurs couches pour le traitement des donn√©es :

1. **Couche de production** : Un producteur Node.js envoie des messages √† un topic Kafka.
2. **Couche de messagerie** : Kafka g√®re la distribution des messages.
3. **Couche de consommation** : Un consommateur Node.js lit les messages du topic Kafka.
4. **Couche de persistance** : Les messages sont stock√©s dans MongoDB.
5. **Couche d'exposition** : Une API REST expose les donn√©es stock√©es.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 ‚îÇ     ‚îÇ                   ‚îÇ     ‚îÇ                 ‚îÇ     ‚îÇ                 ‚îÇ
‚îÇ    Producteur   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ   Apache Kafka    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ  Consommateur   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ     MongoDB     ‚îÇ
‚îÇ    (Node.js)    ‚îÇ     ‚îÇ (Topic test-topic)‚îÇ     ‚îÇ    (Node.js)    ‚îÇ     ‚îÇ                 ‚îÇ
‚îÇ                 ‚îÇ     ‚îÇ                   ‚îÇ     ‚îÇ                 ‚îÇ     ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                                    ‚îÇ
                                                                                    ‚îÇ
                                                                                    ‚ñº
                                                                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                                          ‚îÇ                 ‚îÇ
                                                                          ‚îÇ    API REST     ‚îÇ
                                                                          ‚îÇ   (Express.js)  ‚îÇ
                                                                          ‚îÇ                 ‚îÇ
                                                                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                                                   ‚îÇ
                                                                                   ‚îÇ
                                                                                   ‚ñº
                                                                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                                          ‚îÇ                 ‚îÇ
                                                                          ‚îÇ    Client       ‚îÇ
                                                                          ‚îÇ  (Navigateur)   ‚îÇ
                                                                          ‚îÇ                 ‚îÇ
                                                                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üì¶ Installation pas √† pas

### Pr√©requis
- Node.js (v14 ou sup√©rieure) install√©
- MongoDB install√© et en cours d'ex√©cution
- Apache Kafka 3.9.0 t√©l√©charg√© et extrait

### Configuration de l'environnement de d√©veloppement

1. **Cr√©er un r√©pertoire pour le projet** :
```bash
mkdir kafka-nodejs-project
cd kafka-nodejs-project
```

2. **Initialiser le projet Node.js** :
```bash
npm init -y
```

3. **Installer les d√©pendances n√©cessaires** :
```bash
npm install kafkajs mongoose express
```

4. **Cr√©er les fichiers de base** :
```bash
touch producer.js consumer-db.js api.js
```

## ‚öôÔ∏è Configuration d√©taill√©e

### Configuration de Kafka et Zookeeper

1. **D√©marrer Zookeeper** (dans un terminal d√©di√©) :
   ```bash
   # Sur Windows
   cd chemin/vers/kafka/bin/windows
   zookeeper-server-start.bat ..\..\config\zookeeper.properties
   
   # Sur Linux/Mac
   cd chemin/vers/kafka/bin
   ./zookeeper-server-start.sh ../config/zookeeper.properties
   ```

2. **D√©marrer le serveur Kafka** (dans un autre terminal) :
   ```bash
   # Sur Windows
   cd chemin/vers/kafka/bin/windows
   kafka-server-start.bat ..\..\config\server.properties
   
   # Sur Linux/Mac
   cd chemin/vers/kafka/bin
   ./kafka-server-start.sh ../config/server.properties
   ```

3. **Cr√©er un topic Kafka** (dans un troisi√®me terminal) :
   ```bash
   # Sur Windows
   cd chemin/vers/kafka/bin/windows
   kafka-topics.bat --create --partitions 1 --replication-factor 1 --topic test-topic --bootstrap-server localhost:9092
   
   # Sur Linux/Mac
   cd chemin/vers/kafka/bin
   ./kafka-topics.sh --create --partitions 1 --replication-factor 1 --topic test-topic --bootstrap-server localhost:9092
   ```

4. **V√©rifier que le topic a √©t√© cr√©√©** :
   ```bash
   # Sur Windows
   kafka-topics.bat --list --bootstrap-server localhost:9092
   
   # Sur Linux/Mac
   ./kafka-topics.sh --list --bootstrap-server localhost:9092
   ```

### Configuration de MongoDB

1. **D√©marrer MongoDB** :
   ```bash
   # Le service devrait d√©j√† √™tre en cours d'ex√©cution apr√®s l'installation
   # Si ce n'est pas le cas, sur Windows, vous pouvez d√©marrer le service
   # via Services ou avec la commande :
   net start MongoDB
   
   # Sur Linux :
   sudo systemctl start mongod
   ```

2. **V√©rifier que MongoDB est accessible** :
   ```bash
   # Vous pouvez vous connecter avec MongoDB Compass ou via le shell mongo
   mongo
   # ou
   mongosh
   ```

## üìÅ Structure du projet

```
kafka-nodejs-project/
‚îú‚îÄ‚îÄ node_modules/
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ package-lock.json
‚îú‚îÄ‚îÄ producer.js           # Producteur Kafka
‚îú‚îÄ‚îÄ consumer-db.js        # Consommateur Kafka avec stockage MongoDB
‚îú‚îÄ‚îÄ api.js                # API REST Express
‚îî‚îÄ‚îÄ screenshots/          # Dossier pour les captures d'√©cran (√† cr√©er)
```

## üß† Explication du code

### Producteur (producer.js)

Ce fichier cr√©e un producteur Kafka qui g√©n√®re des messages al√©atoires toutes les 2 secondes et les envoie au topic `test-topic`.

```javascript
const { Kafka } = require('kafkajs');

// Configuration de la connexion √† Kafka
const kafka = new Kafka({
  clientId: 'my-app',
  brokers: ['localhost:9092']
});

const producer = kafka.producer();

// Fonction pour g√©n√©rer un message al√©atoire
function generateRandomMessage() {
  const messages = [
    "Message important du syst√®me",
    "Alerte de s√©curit√©",
    "Mise √† jour disponible",
    "Nouvel utilisateur enregistr√©",
    "Transaction compl√©t√©e"
  ];
  
  const randomIndex = Math.floor(Math.random() * messages.length);
  return messages[randomIndex] + " #" + Math.floor(Math.random() * 1000);
}

// Fonction principale
const run = async () => {
  // Connecter le producteur
  await producer.connect();
  
  // Envoyer un message toutes les 2 secondes
  setInterval(async () => {
    try {
      // G√©n√©rer un message al√©atoire
      const messageValue = generateRandomMessage();
      
      // Envoyer le message au topic
      await producer.send({
        topic: 'test-topic',
        messages: [
          { value: messageValue },
        ],
      });
      console.log('Message produit avec succ√®s:', messageValue);
    } catch (err) {
      console.error("Erreur lors de la production de message", err);
    }
  }, 2000);
};

// Ex√©cuter la fonction principale
run().catch(console.error);
```

**Points cl√©s**:
- Utilisation de `kafkajs` pour se connecter √† Kafka
- G√©n√©ration de messages al√©atoires pour simuler diff√©rents types d'√©v√©nements
- Envoi asynchrone des messages au topic `test-topic`
- Gestion des erreurs avec try/catch

### Consommateur avec MongoDB (consumer-db.js)

Ce fichier cr√©e un consommateur Kafka qui lit les messages du topic `test-topic` et les stocke dans la base de donn√©es MongoDB.

```javascript
const { Kafka } = require('kafkajs');
const mongoose = require('mongoose');

// Connexion √† MongoDB
mongoose.connect('mongodb://localhost:27017/kafka_messages', {
  useNewUrlParser: true,
  useUnifiedTopology: true
})
.then(() => console.log('Connect√© √† MongoDB'))
.catch(err => console.error('Erreur de connexion √† MongoDB:', err));

// D√©finir le sch√©ma pour les messages
const messageSchema = new mongoose.Schema({
  value: String,
  timestamp: { type: Date, default: Date.now }
});

// Cr√©er le mod√®le
const Message = mongoose.model('Message', messageSchema);

// Configuration Kafka
const kafka = new Kafka({
  clientId: 'my-app',
  brokers: ['localhost:9092']
});

const consumer = kafka.consumer({ groupId: 'db-group' });

const run = async () => {
  // Connecter le consommateur
  await consumer.connect();
  
  // S'abonner au topic
  await consumer.subscribe({ topic: 'test-topic', fromBeginning: true });
  
  // Configurer le traitement des messages
  await consumer.run({
    eachMessage: async ({ topic, partition, message }) => {
      // Convertir le message en cha√Æne
      const messageValue = message.value.toString();
      console.log(`Message re√ßu: ${messageValue}`);
      
      // Enregistrer dans MongoDB
      try {
        const newMessage = new Message({ value: messageValue });
        await newMessage.save();
        console.log('Message enregistr√© dans la base de donn√©es');
      } catch (error) {
        console.error('Erreur lors de l\'enregistrement dans MongoDB:', error);
      }
    },
  });
};

// Ex√©cuter la fonction principale
run().catch(console.error);
```

**Points cl√©s**:
- Connexion √† MongoDB avec Mongoose
- D√©finition d'un sch√©ma et d'un mod√®le pour les messages
- Configuration du consommateur Kafka pour lire les messages du topic
- Stockage de chaque message re√ßu dans MongoDB
- Gestion des erreurs pendant le processus

### API REST (api.js)

Ce fichier cr√©e une API REST avec Express.js qui expose les messages stock√©s dans MongoDB.

```javascript
const express = require('express');
const mongoose = require('mongoose');
const app = express();
const port = 3000;

// Connexion √† MongoDB
mongoose.connect('mongodb://localhost:27017/kafka_messages', {
  useNewUrlParser: true,
  useUnifiedTopology: true
})
.then(() => console.log('API connect√©e √† MongoDB'))
.catch(err => console.error('Erreur de connexion √† MongoDB:', err));

// D√©finir le sch√©ma pour les messages
const messageSchema = new mongoose.Schema({
  value: String,
  timestamp: { type: Date, default: Date.now }
});

// Cr√©er le mod√®le
const Message = mongoose.model('Message', messageSchema);

// Middleware pour parser le JSON
app.use(express.json());

// Route pour obtenir tous les messages
app.get('/api/messages', async (req, res) => {
  try {
    // R√©cup√©rer tous les messages, tri√©s par date d√©croissante
    const messages = await Message.find().sort({ timestamp: -1 });
    res.json(messages);
  } catch (error) {
    res.status(500).json({ error: 'Erreur lors de la r√©cup√©ration des messages' });
  }
});

// Route pour obtenir un message sp√©cifique par ID
app.get('/api/messages/:id', async (req, res) => {
  try {
    // R√©cup√©rer un message par son ID
    const message = await Message.findById(req.params.id);
    if (!message) {
      return res.status(404).json({ error: 'Message non trouv√©' });
    }
    res.json(message);
  } catch (error) {
    res.status(500).json({ error: 'Erreur lors de la r√©cup√©ration du message' });
  }
});

// D√©marrer le serveur
app.listen(port, () => {
  console.log(`API REST d√©marr√©e sur http://localhost:${port}`);
});
```

**Points cl√©s**:
- Configuration d'Express.js pour cr√©er une API REST
- Connexion √† la m√™me base de donn√©es MongoDB que le consommateur
- D√©finition des routes pour r√©cup√©rer les messages
- Gestion des erreurs pour chaque endpoint
- Tri des messages par date pour afficher les plus r√©cents en premier

## üöÄ Ex√©cution du syst√®me

Pour ex√©cuter l'ensemble du syst√®me, suivez ces √©tapes dans l'ordre :

1. **D√©marrer Zookeeper et Kafka** (voir section Configuration)

2. **D√©marrer l'API REST** (dans un terminal) :
   ```bash
   cd kafka-nodejs-project
   node api.js
   ```
   Vous devriez voir : `API REST d√©marr√©e sur http://localhost:3000`

3. **D√©marrer le consommateur** (dans un autre terminal) :
   ```bash
   cd kafka-nodejs-project
   node consumer-db.js
   ```
   Vous devriez voir : `Connect√© √† MongoDB`

4. **D√©marrer le producteur** (dans un troisi√®me terminal) :
   ```bash
   cd kafka-nodejs-project
   node producer.js
   ```
   Vous devriez voir des messages comme : `Message produit avec succ√®s: Alerte de s√©curit√© #123`

5. **V√©rifier que le flux fonctionne** :
   - Le producteur envoie des messages √† Kafka
   - Le consommateur lit ces messages et les stocke dans MongoDB
   - L'API REST permet d'acc√©der √† ces messages via HTTP

## üåê API REST et endpoints

L'API REST expose les endpoints suivants :

### GET /api/messages
R√©cup√®re tous les messages stock√©s dans MongoDB, tri√©s par date de cr√©ation (du plus r√©cent au plus ancien).

**Exemple de requ√™te** :
```
GET http://localhost:3000/api/messages
```

**Exemple de r√©ponse** :
```json
[
  {
    "_id": "6123456789abcdef01234567",
    "value": "Alerte de s√©curit√© #123",
    "timestamp": "2025-04-21T15:30:45.123Z",
    "__v": 0
  },
  {
    "_id": "6123456789abcdef01234568",
    "value": "Transaction compl√©t√©e #456",
    "timestamp": "2025-04-21T15:30:43.456Z",
    "__v": 0
  },
  // ...
]
```


![Exemple de get message](screenshots/postman1.png)


### GET /api/messages/:id
R√©cup√®re un message sp√©cifique par son ID MongoDB.

**Exemple de requ√™te** :
```
GET http://localhost:3000/api/messages/6123456789abcdef01234567
```

**Exemple de r√©ponse** :
```json
{
  "_id": "6123456789abcdef01234567",
  "value": "Alerte de s√©curit√© #123",
  "timestamp": "2025-04-21T15:30:45.123Z",
  "__v": 0
}
```


![Exemple de get message](screenshots/postman2.png)


## üß™ Test des fonctionnalit√©s

### Test du producteur
Le producteur devrait afficher des messages dans la console indiquant que des messages sont produits avec succ√®s.

### Test du consommateur
Le consommateur devrait afficher des messages indiquant qu'il re√ßoit des messages et les enregistre dans la base de donn√©es.

### Test de l'API REST
Vous pouvez tester l'API REST de plusieurs fa√ßons :

1. **Navigateur web** : Acc√©dez √† `http://localhost:3000/api/messages`
2. **Curl** (dans un terminal) :
   ```bash
   curl http://localhost:3000/api/messages
   ```
3. **Postman** ou outil similaire :
   - Cr√©ez une nouvelle requ√™te GET
   - D√©finissez l'URL sur `http://localhost:3000/api/messages`
   - Cliquez sur "Send"

![Exemple de get message](screenshots/postman1.png)

### V√©rification dans MongoDB
Vous pouvez √©galement v√©rifier directement dans MongoDB que les messages sont bien stock√©s :

![Exemple de mongodb](screenshots/mongo.png)





## üìö Ressources

- [Documentation officielle de Kafka](https://kafka.apache.org/documentation/)
- [Documentation de KafkaJS](https://kafka.js.org/)
- [Documentation de Mongoose](https://mongoosejs.com/docs/)
- [Documentation d'Express](https://expressjs.com/fr/)
- [Tutoriel MongoDB](https://docs.mongodb.com/manual/tutorial/)