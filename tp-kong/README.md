# ğŸš€ TP8 : Microservices avec API Gateway Dynamique

## ğŸ“ Description du projet
Ce projet dÃ©montre la mise en place d'une architecture de microservices utilisant Kong comme API Gateway dynamique en mode DB-less. Il comprend deux microservices REST dÃ©veloppÃ©s en Node.js :
- **Service A (Users)** : Fournit des informations sur les utilisateurs
- **Service B (Products)** : Fournit des informations sur les produits

## ğŸ“‚ Structure du projet
```
tp-kong/
|-- service-a/
|   |-- Dockerfile
|   |-- package.json
|   |-- index.js
|-- service-b/
|   |-- Dockerfile
|   |-- package.json
|   |-- index.js
|-- kong.yml
|-- docker-compose.yml
|-- README.md
```

## ğŸ§© Composants du projet

### ğŸ”Œ Microservices
1. **Service A (Users)** ğŸ‘¤
   - Port: 3001
   - Endpoint: `/users`
   - Retourne une liste d'utilisateurs au format JSON

2. **Service B (Products)** ğŸ›’
   - Port: 3002
   - Endpoint: `/products`
   - Retourne une liste de produits au format JSON

### ğŸŒ‰ Kong API Gateway
- Kong est configurÃ© en mode DB-less via un fichier de configuration dÃ©claratif
- Routes les requÃªtes vers les microservices appropriÃ©s:
  - `/users` -> Service A
  - `/products` -> Service B

## ğŸ“„ Fichiers importants

### service-a/index.js
```javascript
const express = require('express');
const app = express();
const PORT = 3001;
const users = [ { id: 1, name: 'Alice' }, { id: 2, name: 'Bob' } ];

app.get('/', (req, res) => res.json(users));

app.listen(PORT, () => console.log(`Service A running on port ${PORT}`));
```

### service-b/index.js
```javascript
const express = require('express');
const app = express();
const PORT = 3002;
const products = [ { id: 1, name: 'Laptop', price: 999 }, { id: 2, name: 'Phone', price: 699 } ];

app.get('/', (req, res) => res.json(products));

app.listen(PORT, () => console.log(`Service B running on port ${PORT}`));
```

### Dockerfile (pour les deux services)
```dockerfile
FROM node:22-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install --production
COPY index.js ./
EXPOSE 3001  # 3002 pour service-b
CMD ["node", "index.js"]
```

### kong.yml
```yaml
_format_version: "1.1"
services:
  - name: service-a
    url: http://service-a:3001
    routes:
      - name: users-route
        paths: ["/users"]
  - name: service-b
    url: http://service-b:3002
    routes:
      - name: products-route
        paths: ["/products"]
```

### docker-compose.yml
```yaml
services:
  service-a:
    build: ./service-a
    networks:
      - kong-net

  service-b:
    build: ./service-b
    networks:
      - kong-net

  kong:
    image: kong:latest
    environment:
      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /etc/kong/kong.yml
    volumes:
      - ./kong.yml:/etc/kong/kong.yml:ro
    ports:
      - "8000:8000" # Proxy
      - "8001:8001" # Admin API
    networks:
      - kong-net

networks:
  kong-net:
    driver: bridge
```

## ğŸš€ Instructions de dÃ©ploiement

1. **Lancer les conteneurs** ğŸ³
   ```bash
   docker compose up -d --build
   ```

2. **VÃ©rifier l'Ã©tat des services** ğŸ”
   ```bash
   docker compose ps
   ```

3. **Tester les endpoints via curl** ğŸŒ
   ```bash
   curl http://localhost:8000/users
   curl http://localhost:8000/products
   ```

## âœ… RÃ©sultats des tests

Voici le rÃ©sultat des tests effectuÃ©s avec curl :

![RÃ©sultats des tests](res.png)

## âš™ï¸ Mode de fonctionnement

1. ğŸ“± Les requÃªtes client arrivent sur Kong (port 8000)
2. ğŸ§­ Kong route ces requÃªtes vers le microservice appropriÃ© en fonction du chemin
3. ğŸ”„ Les microservices traitent les requÃªtes et renvoient les rÃ©sultats
4. ğŸ“¤ Kong transmet ces rÃ©sultats au client

## ğŸ—„ï¸ Kong en mode DB-less

Kong est configurÃ© en mode DB-less, ce qui signifie :
- ğŸ”Œ Pas de dÃ©pendance Ã  une base de donnÃ©es externe
- ğŸ“ Configuration via un fichier dÃ©claratif (kong.yml)
- ğŸš€ Plus simple Ã  dÃ©ployer et Ã  mettre Ã  l'Ã©chelle
- ğŸ’» IdÃ©al pour les environnements de dÃ©veloppement et les petits dÃ©ploiements

## ğŸ Conclusion

Ce projet dÃ©montre comment Kong peut Ãªtre utilisÃ© comme API Gateway pour simplifier la gestion des microservices. Les principaux avantages incluent :
- ğŸ§­ Routage centralisÃ©
- ğŸ§© SÃ©paration claire des prÃ©occupations entre les services
- ğŸ³ FacilitÃ© de dÃ©ploiement avec Docker Compose
- âš™ï¸ Configuration dÃ©clarative simple